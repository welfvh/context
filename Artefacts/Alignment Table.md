| Field | Core Question | Focus | Key Concerns | Examples |
| :---- | :---- | :---- | :---- | :---- |
| **Technical Alignment** | How can we make AI systems reliably optimize for specified objectives? | Machine learning architectures, training processes, reward specification | Inner/outer alignment, reward hacking, specification gaming | Work on reward modeling, scalable oversight, mechanistic interpretability |
| **Value Learning/Value Alignment** | How do we get AI systems to learn and act according to human values? | Value learning, preference learning, value extrapolation | Value specification, human feedback limitations, value uncertainty | Inverse reinforcement learning, debate, amplification, CEV |
| **Moral Philosophy** | What is good/right/valuable? What constitutes genuine wisdom? | Theories of value, meta-ethics, moral uncertainty | Nature of value, moral realism vs anti-realism, aggregation of values | Population ethics, suffering-focused ethics, theories of consciousness |
| **Social Choice Theory** | How can we aggregate individual preferences into collective decisions? | Voting systems, preference aggregation, mechanism design | Impossibility theorems, strategic behavior, preference revelation | Moral parliament approaches, value learning from groups |
| **Socio-technical Alignment** | How do we ensure beneficial outcomes when AI systems are embedded in social contexts? | Interaction between AI systems and social structures/institutions | Fairness, transparency, accountability, deployment contexts | Algorithmic fairness research, participatory design methods |
| **AI Governance & Policy** | What governance structures and mechanisms do we need for beneficial AI development? | Institutional design, policy frameworks, coordination mechanisms | Racing dynamics, coordination failures, deployment oversight | Standards development, monitoring systems, international coordination |
| **Systemic Safety** | How do we ensure safety in multi-agent systems and competitive dynamics? | Emergent behaviors, game theoretic dynamics, competitive pressures | Arms races, coordination problems, systemic risks | Multi-polar scenarios, cooperative AI, bargaining mechanisms |
| **“Alignment at Large” / CETAI** | How do we align civilization's fundamental optimization processes toward life-affirming ends? | Civilizational-scale dynamics, Moloch, technological capitalism as unconscious autonomous superintelligence | Financial totalization, market incentives, unconscious optimization pressures | \[emerging area with limited formal research\] |