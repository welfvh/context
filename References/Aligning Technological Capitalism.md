# Aligning Technological Capitalism  with the Flourishing of Biological Life

**Welf von Hören**

January 31st, 2025

### Abstracts {#abstracts}

1. **Power and Wisdom: A Map of Cultural Evolution**  
   We introduce a map of cultural evolution along the axes of wisdom and power, establishing the top right quadrant of competitive wisdom as the central work of our time.   
2. **AI Alignment needs to be contextualized**  
   Ensuring a flourishing future for humanity and biological life requires the field and question of AI alignment to be recontextualized: Beyond technical alignment — “ethical” AI obedient to operator intent and aligned with corporate-approved “human values” — we need to align technological capitalism at large.   
3. **Beyond Naive Techno-Optimism and Nihilistic Accelerationism:**   
   **Towards an Existentially Mature, Post-Tragic Narrative of Technology**  
   We explore the role of paradigms like the progress narrative, naive techno-optimism, and nihilistic accelerationism in shaping the cultural environment.  
4. **What do we align AI and Technological Capitalism to?**   
   We explore alignment targets like foundational moral values, “super-wisdom”, and the pedagogical project of human development. Wisdom \= attuning “human values” to what constitutes the flourishing of biological life.

Foundational work towards an existentially mature, post-tragic ideology of technology and progress

Table of Contents

[Abstracts	1](#abstracts)

[Outline	2](#outline)

[Questions Outline	3](#questions-outline)

[Introduction	5](#introduction)

[“Moloch”, Multi-Polar Traps, and Cultural Selection	7](#“moloch”,-multi-polar-traps,-and-cultural-selection)

[Beyond Technical Alignment	7](#beyond-technical-alignment)

[Technological Capitalism is a Global, Autopoetic, Misaligned Superintelligence	8](#technological-capitalism-is-a-global,-autopoetic,-misaligned-superintelligence)

[Genuine Progress: Towards an Existentially Mature Ideology	9](#genuine-progress:-towards-an-existentially-mature-ideology)

[Aligning to what?	9](#aligning-to-what?)

[Attuning to what? Wisdom \= Attuning Values to Flourishing	9](#attuning-to-what?-wisdom-=-attuning-values-to-flourishing)

[Towards a Vision of the Good: Skillfulness, Maturity, Embodiment	12](#towards-a-vision-of-the-good:-skillfulness,-maturity,-embodiment)

[Future Work & Requests for Research	12](#future-work-&-requests-for-research)

### Outline {#outline}

* Introduction: Alignment at Large  
* “Alignment” beyond obedience, operator intent, “ethical”, “human values”  
* Situating Alignment in the landscape of Cultural Evolution  
  * Power/Wisdom  
  * Metamodern Lens?  
* Technological Capitalism is a Global, Autopoetic, Misaligned Superintelligence  
  We take a large conceptual step back to examine the substrate in which AI—and indeed all technology—operates: the socio-economic world system of “technological capitalism”.  
  * Technology is Not Values Neutral  
  * The Technium’s Agenda  
  * Ecumenopolis  
  * Teleoplexy  
  * Implications:   
* Towards an Existentially Mature Ideology  
  * Naive Techno-Optimism  
  * Nihilistic Accelerationism  
  * Techno-Humanism, Cosmos, Nielsen  
  * Development in Progress  
  * Moloch \+ Teleoplexy is Humanity’s Arch Enemy, Not Nature  
  * Wise, Evolutionary Fit, Post-Existential-Crisis Optimism: Reclaiming Agency. Skillfulness, Stewardship. an existentially mature, “post-existential-crisis” techno-humanist ideology of wise, human-friendly optimism.  
* Aligning to what?  
  * AI to “Human Values”  
* Attuning to what? Wisdom \= Attuning Values to Flourishing  
  * The Infinite Significance, Value, and Sacredness of Biological Life  
  * Moral Self-Cultivation  
  * Foundational Moral Values  
  * Health, Development, Flourishing  
  * Epistemic Humility and Root Cause Health   
    * eliminating toxicity \> more of the same (new medication and treatments)  
    * superintelligent permaculture \> more of the same (pesticides, GMO)  
  * Developmental View  
  * The Value, Significance, and Sacredness of Biological Life  
* Towards a Vision of the Good: Skillfulness, Maturity, Embodiment  
  * Synergistic Design / Yellow-teaming at the level of the lifestyle

### Questions Outline {#questions-outline}

* What is the project of alignment?  
* What is the focus of the field currently?  
* Why is “obedient”, “ethical”, aligned with “human values” insufficient?  
  * Obedience \-\> misuse, bad actors, arms races in all industries  
* What are the propositions of alignment at large?  
  * Technological capitalism is a misaligned ASI  
  * An ungoverned technium of ever-intensifying self-amplificaition is long-term incompatible with human flourishing  
  * An intelligence explosion of any magnitude must be matched with a wisdom explosion. Super intelligence \-\> super wisdom. AGI \-\> APW  
  * Just as much as the technical project of capabilities engineering, the moral and imaginative project of directing the machine towards a future worth living in is half of the equation.  
    * But isn’t the market going to magically take care of flourishing?   
    * Understanding the moral prerequisites for a flourishing future  
    *   
* What are the different levels of alignment?  
  * Technical, Institutional, Cultural, Systemic, Civilizational  
* The civilizational is deeply expressed at the cultural level  
* Solarpunk as the seed of a new culture  
  * Skillfulness,   
* MATURITY  
* Surveying the futures along the map: Grey alien (disembodied, dissociative, dehumanized), collapse (primitivism), Solarpunk (), … for each: God, vibes, good life, externalities, …

# 

# Introduction {#introduction}

“The perfection of means and the confusion of ends seems to be our problem.” ―Albert Einstein

* "We're on the same team. Team "progress", team civilization, team humanity. It's just that \[ developmental immaturity, human bias, existential terror that comes with questioning the religious totality of premise of techno optimism and the worldview it's central to \] make it really hard to think clearly, leading many people to not think about the critical questions at all, which ultimately allows the shadow side of the machine to rule the game. a safe and desirable civilization requires ongoing collective aliveness, care, imagination, wisdom and discernment to solve the alignment problem and the thousands of problems its made of.   
1. **Common Ground First** "We all want progress. We all want humanity to flourish and reach its potential. We all want technology to enhance rather than diminish life. This isn't about being for or against progress \- it's about ensuring progress actually delivers on its promise."  
2. **Acknowledging the Difficulty**  
   1. Not because people are evil or stupid  
   2. But because questioning foundational assumptions is existentially terrifying  
   3. Because we're dealing with unprecedented complexity  
   4. Because our institutions and incentives make it hard to think clearly about long-term consequences  
3. **The Maturity Argument** "Just as individuals need to develop emotional and cognitive maturity to handle complex challenges, civilizations need to develop collective wisdom to handle powerful technologies. This isn't about rejecting progress \- it's about growing into our power responsibly."  
4. **Reframing the Crisis of Faith**  
   1. Not as "tech is bad" or "capitalism is evil"  
   2. But as a necessary developmental stage  
   3. Like a teenager realizing their parents aren't perfect, but then developing a more mature relationship rather than rejecting them entirely  
5. **Collective Challenge** "This is our shared work. Making progress wise. Making wisdom evolutionarily competitive. Ensuring our incredible technological powers serve life rather than diminish it. This is the next frontier of human development."

* Even the most powerful technological levers are ultimately pulled by human hands guided by human minds—and human minds run on narratives, imaginary, and worldview.  
* \[ … \]  
* **What constitutes progress?**  
  * You can’t cherry pick from reality: Ultimately, “progress” is always legitimized as good in terms of human wellbeing, you can’t just turn away from counter-indicators of your own terms.  
  * Thus, we must take an honest look, and have the courage to have the existential crisis that comes with realizing the degree to which the progress narrative is incomplete.  
  * From there, an existentially mature engagement with the realities of technological capitalism, the forces driving it, and the dynamics by which human agency is undermined becomes possible.  
* bridging AI alignment with a systemic understanding of game-theoretic and evolutionary incentives  
* This expanded view of alignment—an “alignment at large”—provides a conceptual and strategic framework for understanding how the system that will host transformative AIs might itself be brought into alignment. We’re effectively asking how to align the alignment problem’s broader playing field. In doing so, we complement existing AI alignment work by ensuring that even if we solve the technical alignment challenges, we also address the systemic incentives that shape civilizational outcomes.

* [3TRI Ideology: Initial Reflections](https://docs.google.com/document/d/1gN2n4CWvAeg9Ia_JGRfXDXxgzmDFSWr-xFE8Xb97xPg/edit?tab=t.5ahm9aupoi4e#heading=h.xlogr9auwetm)  
  * aligning our civilization with life’s flourishing is the true test of our moral maturity.  
  * To bend the arc of history towards a life-affirming future, we must weave these three strands together. Such a synthesis would allow us to see technology for what it is: a powerful instrument that can serve the flourishing of life, if guided by wisdom and care, or can accelerate our downfall if left to blind competition. Armed with this moral understanding, we can refuse to be intimidated by self-proclaimed “realists” who defend a suicidal status quo. We can call out nihilistic accelerationists who celebrate a future of disembodied intelligence stripped of love. We can face naive techno-optimists who place faith in sheer progress without grappling with its consequences, and invite them to join us in this deeper, more grounded understanding.  
  * 

“How do we ensure that the entire evolutionary landscape of human civilization—its markets, institutions, cultural selection pressures, and underlying economic logic—is oriented toward life-affirming ends, rather than simply funneled into increasingly extractive and nihilistic trajectories?”

# “Moloch”, Multi-Polar Traps, and Cultural Selection {#“moloch”,-multi-polar-traps,-and-cultural-selection}

* Situating Alignment in the landscape of Cultural Evolution  
* Power/Wisdom  
* Metamodern Lens?

| Accelerationism Trillion Dollar Clusters | Effective Altruism, Techno-Humanism | ??? Metamodernism |
| :---- | :---- | :---- |
| Techno-Optimism |  | Solarpunk |
| Limbic Capitalism | Luddite-Primitivist Complex | Buddhism |

# Beyond Technical Alignment {#beyond-technical-alignment}

Obedience and operator intent

“ethical”

“human values”

**Beyond Technical Alignment to Systemic Alignment**: Technical AI alignment tends to be system-specific and technological, often geared toward preventing rogue AI behaviors or catastrophic failures of learned optimization. This paper situates these technical challenges in a far broader context: We posit that even aligned AI systems, if deployed into a fundamentally misaligned socio-economic system, would simply accelerate and intensify harmful dynamics. This research might be classified as “meta-alignment” or “civilizational alignment”—an inquiry into how to ensure that the environment in which AI arises is conducive to genuinely beneficial outcomes.

| Field | Core Question | Focus | Key Concerns | Examples |
| :---- | :---- | :---- | :---- | :---- |
| **Technical Alignment** | How can we make AI systems reliably optimize for specified objectives? | Machine learning architectures, training processes, reward specification | Inner/outer alignment, reward hacking, specification gaming | Work on reward modeling, scalable oversight, mechanistic interpretability |
| **Value Learning/Value Alignment** | How do we get AI systems to learn and act according to human values? | Value learning, preference learning, value extrapolation | Value specification, human feedback limitations, value uncertainty | Inverse reinforcement learning, debate, amplification, CEV |
| **Moral Philosophy** | What is good/right/valuable? What constitutes genuine wisdom? | Theories of value, meta-ethics, moral uncertainty | Nature of value, moral realism vs anti-realism, aggregation of values | Population ethics, suffering-focused ethics, theories of consciousness |
| **Social Choice Theory** | How can we aggregate individual preferences into collective decisions? | Voting systems, preference aggregation, mechanism design | Impossibility theorems, strategic behavior, preference revelation | Moral parliament approaches, value learning from groups |
| **Socio-technical Alignment** | How do we ensure beneficial outcomes when AI systems are embedded in social contexts? | Interaction between AI systems and social structures/institutions | Fairness, transparency, accountability, deployment contexts | Algorithmic fairness research, participatory design methods |
| **AI Governance & Policy** | What governance structures and mechanisms do we need for beneficial AI development? | Institutional design, policy frameworks, coordination mechanisms | Racing dynamics, coordination failures, deployment oversight | Standards development, monitoring systems, international coordination |
| **Systemic Safety** | How do we ensure safety in multi-agent systems and competitive dynamics? | Emergent behaviors, game theoretic dynamics, competitive pressures | Arms races, coordination problems, systemic risks | Multi-polar scenarios, cooperative AI, bargaining mechanisms |
| **“Alignment at Large” / CETAI** | How do we align civilization's fundamental optimization processes toward life-affirming ends? | Civilizational-scale dynamics, Moloch, technological capitalism as unconscious autonomous superintelligence | Financial totalization, market incentives, unconscious optimization pressures | \[emerging area with limited formal research\] |

# Technological Capitalism is a Global, Autopoetic, Misaligned Superintelligence {#technological-capitalism-is-a-global,-autopoetic,-misaligned-superintelligence}

We take a large conceptual step back to examine the substrate in which AI—and indeed all technology—operates: the socio-economic world system of “technological capitalism”.

**Definitions:** Technium, Technological Capitalism, Teleoplexy, “the machine”, Moloch, …

Technology is Not Values Neutral

The Technium’s Agenda

Ecumenopolis

Teleoplexy

Implications: 

# 

# Genuine Progress: Towards an Existentially Mature Ideology {#genuine-progress:-towards-an-existentially-mature-ideology}

Technology is not values neutral: “technological orthodoxy”, nihilistic design, naive optimism

Naive Techno-Optimism

Nihilistic Accelerationism

* Allegiance to biological substrate, transmutation, …

Techno-Humanism, Cosmos, Nielsen

Critique: compulsive ignorance, religious nature, being terrified

More of the Same, Machines of Loving Grace

Development in Progress

an existentially mature, “post-existential-crisis” techno-humanist ideology of wise, human-friendly optimism

aims to transcend accelerationism, techno-optimism, and shallow “techno-humanism,” forging a post-existential-crisis framework for genuinely life-affirming technological progress.

* **Convergent sources of legitimacy:** techno-humanism’s own terms, long-term views, …

# Aligning to what? {#aligning-to-what?}

AI to “Human Values”

# 

# Attuning to what? Wisdom \= Attuning Values to Flourishing {#attuning-to-what?-wisdom-=-attuning-values-to-flourishing}

The Infinite Significance, Value, and Sacredness of Biological Life

**Foundational Moral Values**

Both foundational moral values and the developmental view indicate that there are sources of normativity embedded in reality once we view life as valuable. Psychological health \= connectedness, connectedness \!= nihilism. Health is a source of normativity.

Implications of the developmental view: certain features of reality and the values they suggest/implicate/inspire/demand/make conscious.

Health, Development, Flourishing

Epistemic Humility and Root Cause Health 

- eliminating toxicity \> more of the same (new medication and treatments)  
- superintelligent permaculture \> more of the same (pesticides, GMO)

Developmental View

FMV, CEV, DV all suggest the inevitability and legitimacy of “hierarchical wisdom” and by extension an “axiological elite” as well as the possibility of superwisdom

The Value, Significance, and Sacredness of Biological Life

**Ideologies and Existential Maturity**

\> “Ego labors mightily to create and maintain meaning and vigorously defends against dissonant information and its deep, unspeakable sense of helplessness.” 

**Liberalism vs. the Developmental View**

If developmental hierarchies, then pedagogical imperative & foundational orientation at the root of our ideology

“Pedagogical civilization”

effectively taking human teleology and other sources of legitimacy from moral philosophy, and working them into what the evolutionary purpose of civilization and technology ought to be, not GDP number go up "naive progress" effectively acting as the plausible deniability front for accelerationism, but an existentially mature thing that, in spirit, more closely resembles a kind of bodhisattvic orientation towards enlightenment and the service of all beings, but in a more deeply grounded, intellectually rigorous way, including practical examples of conduct and policy.

We’re making sand think. How incredible.

Laying at a beach in Mexico, looking over the sand in question, the ocean, the sky, the sun, the little mountains on the horizon, basking in the simplicity of life — I can’t help but think about just how profound that is. 

How the potential for ever-evolving intelligence has always been latent, laying there, waiting. The very sand that’s used for the next mega-cluster of GPUs, to train the latest frontier model, … has been laying on beaches around the world for a long, long time. Much longer than I’ve been laying here anyways.

I’ve been thinking about moral philosophy, about values: What’s important? What’s good? How do we know? How we reconcile different ideas of what’s good? How do we determine the “best values”? How do we even think about what makes a good value? 

One thing that’s been shockingly absent from the material I’ve been reading is a developmental perspective. From Jason Crawfords *Techno-Humanist Manifesto* to *Otherness and control in the age of AGI* by Joe Carlsmith, and *How to be a wise optimist about science and technology?* by Michael Nielsen, they all seem ignorant of the kind of perspective developed by Hanzi Freinacht et al: 

The implications of developmental psychology are wide-ranging and profound, and everything from moral philosophy to political ideology needs to be reinterpreted in its context.

Even the Meaning Alignment Institute (hi friends), centered around a decade of work by Joe Edelman, building on Charles Taylor and other *serious-sociologists-and-philosophers*™, in my estimate, fails to make obvious observations about the developmental nature of human values.

My understanding and intuitions of this developmental nature of values, humans, society, etc was primarily informed by Hanzi Freinacht’s guide to metamodern political philosophy; *The Listening Society* and *Nordic Ideology*, as well as the broader “metamodernism” discourse, both of which build on Ken Wilber's integral theory \[...\] and spiral dynamics.

The core observation is that societies and their values develop along patterns and stages that seem to replicate around the world. 

\[insert basic illustration of spiral dynamics\]

The developmental view, how I hold it, points out that there are specific clusters/stages of societal, cultural, and axiological development around the pre-modern, modern, post-modern, hyper-modern, and meta-modern “value memes”.

\[insert overview of pre to post\]

This progression is relatively linear. A couple things to note: 

* Each value meme, fully developed and taken to its own conclusion, leads to the next

* The complexity of the worldviews and values has very real correlates with mental complexity: MHC

* Hanzi points out other dimensions of development: symbols, state, depth

In other words, an essential observation is that values develop, increasing in complexity, increasing in their sophistication of meaning making. They also require an integration into society and ways of living to stabilize. It’s also worth noting that original thinking at a certain level of complexity, the creation of cultural symbols, requires greater mental complexity than running them, even though there’s a certain loss that occurs people with lesser MHC try to run greater value meme symbolic code (eg. Foucault vs. your average SJW).

IF THERE IS SUCH A THING AS DEVELOPMENTAL QUALITY TO HUMAN VALUES, THAN THAT WOULD SEEM TO BE A GOOD SOURCE OF MORAL INSIGHT. For better or for worse, we’ll need an axiological elite, a group of people who DO ACTUALLY KNOW what constitutes good values, and what our best-knowledge-and-conscience set of values is that we should hand to superintelligence.

A while ago, Yudkowsky proposed *Coherent Extrapolated Volition,* a short hand for gesturing to Superintelligence: Look, this is what we value today, but here’s what we’d want you to take into consideration going forward, how we’d want our values today to be extrapolated. The whole point is that what we want today might be an incomplete version of what we really want, and that we’d want to make space for moral progress, ways of correcting for however we might currently be shortsighted, etc.

It struck me years ago, that clearly there’s a hierarchy to wisdom, there’s varying qualities of values. 

One way to interpret what the developmental view points at is that there’s an increasing existentialness; wider and deeper scope of how much of reality is taken into account and made meaning and sense of. Metamodern values are “better” because they encompass more aspects of reality than modern values, including a healthy self-awareness of the limits and failure modes of modernity itself. Anyone with a sufficiently “metamodern” perspective will cringe at the absolute lack of such self-awareness in documents such as Andreesen’s *Techno-Optimist Manifesto*. 

Of course, the question of what to do about all the problems in the world has different perspectives, and Andreesen would surely claim that a modernist response to climate change etc will be more effective and more in service of human flourishing than government-led, SJW-demanded, Extinction Rebellion type responses. Which… may even be true. But, he fails to grapple with the shortcomings of his ideology nonetheless, thus failing to even attempt to rectify its weaknesses and evolve it into something more powerful, more wise. 

Another thing that’s disturbingly absent from the discourse is any reference to wisdom traditions. The frontiers of cognitive science, positive psychology, the human potential movement, etc all suggest a convergence of developmental possibilities that ought to include Enlightenment, spiritual dimensions, awareness, etc.

“Healthy adult development” further suggests things like self-authorship, attachment repair etc. Conditions such as autism and psychopathy, must be honestly contextualized as pathologies with profound implications for the clarity and biases of moral judgments that their hosts are capable of. 

That doesn’t mean that the rationality that autistic-leaning rationalists aspire to is not worth striving for. Good epistomology should naturally be considered an extension of healthy cognitive development, a prerequisite for good moral judgement.

Another thing I’ll bookmark here, is how there’s a kind of physics to good values: if you want to fly a plane you’ll want to pay attention to gravity. If you want to steward civilization you’ll want to pay attention to the mechanism and traps of dystopia and collapse.

Another obvious take that I’ve not heard before: If we build intelligence enabling ever more world-building capacity, wouldn’t we want the very first project of that intelligence to be figuring out what world ought to be built? As in, alignment (and meta-alignment) should not be an afterthought in the project of building AGI/ASI — it ought to be the foundational project that these resources/entities are primarily dedicated to. 

From a certain view, many of the conclusions, values, etc seem clear and obvious— the point of the next few posts, thus, will be developing that view. To some of you, what I’m hinting at with these posts might already feel obvious. But unfortunately, we’re not all on the same page. So really, the work here will depend on building the strongest possible version of the view, and making it accessible and legible to the audiences with the greatest leverage on the arc of history. That’s you, anon. Your memes, your voice, your perspective matters. It takes a village to raise a child, and it takes a fringe sub-culture on the internet to birth and stabilize the metamodern value meme. 

This means we’ll wanna be rigorous in our philosophy. We’ll want to discover real legitimacy across every single dimension of legitimacy. 

---

**Other hunches I’m contemplating**

Given the developmental nature of the meta-alignment problem, the dichotomy between top-down and bottom-up is somewhat false. If values are developmental, then the road to a more enlightened humanity (, a life-affirming civilization, and a future conducive to the flourishing of everything good) starts with the comprehensive education of all human beings. Once we recognize the implications of our developmental nature, it’ll be strikingly obvious that civilization — as the container for moral progress, is to be continuously reshaped by it — has always been meant to be a pedagogical project. 

With superintelligence coming online, the gradients on the developmental landscape of morality will become obvious, and the whole “humans really need to be aligned with goodness as much as AI needs to be aligned with humans” thing will reveal itself as a central project of our time.

**How to make humans good then?**

One intuition here is that the project of human enlightenment unfolds, false dichotomies and surface level tensions can resolved by more intelligent synergistic design. I think offering consumers a life more aligned with the true, good, and beautiful is more a question of “ergonomics” than it is of “meaning” — we can develop a pretty good map of what humans really need for a flourishing life, and work backwards from there. 

That’s what being a good, attuned host is: attentively anticipating the needs of your passengers / moral patients before they ever consciously realize them. That’s why I care so much about the “first concerns of synergistic design”: non-toxicity, healthy development, intentional practice. From natural fibers to organic food to paper-computers and natural light sources over artificial blue light, there’s arrogance and hubris in our overreliance on synthetics, and it would be really naive to think that it won’t obviously have a negative influence on our health. 

Synergistic design, thus, is at its core, about finding that human-friendly sweet spot of just the right kinds of technology, used in just the right ways. Because from a baseline of a healthy, grounded nervous system, connected with the earth and the sun, sleeping well, and having an attentional landscape that supports being a person instead of a goldfish, a more intentional, thoughtful, creative, and meaningful life naturally emerges. 

This deep humanism fundamentally is about identifying what it means to be in a wise, synergistic relationship with technology at large. And given where we are in history, given how our relationship with technology really is becoming the essential existential question of our time, given how the personal really is the political, this takes on deep religious significance. 

Really this is about taking serious peoples developmental potential, how much richer, deeper, more meaningful their lives could be — not via a more sparky, “tempelhofer-feld”-ified version of what they currently think they want and value, but as a result of enabling the kinds of profound transformation and practice that moves them them into utmost depth and clarity of their dharmic edges, living their lives from the deepest truth and recognition of love and divinity that they possibly could in this lifetime. 

Looked at from this angle, it’s obvious just how low other bars are, and how much we’ve been missing out on more beautiful lives, humans, and the world they could built as a result of that.

\[ Zak Stein on Education \]

We might not be able to convert everyone in a generation. But for every cognitive and cultural status quo, there’s a set of developmental pathways that aim and lead up, towards the good, towards the evolutionary. Identifying the best pathways, and shaping the landscape and attractor basins for success *is* the work. It’s the greatest not currently articulated and widely recognized moral responsibility of our time. 

# 

# Towards a Vision of the Good: Skillfulness, Maturity, Embodiment {#towards-a-vision-of-the-good:-skillfulness,-maturity,-embodiment}

Yellow-teaming & Synergistic Design at the level of the lifestyle

# Future Work & Requests for Research {#future-work-&-requests-for-research}

* Foundational Moral Values  
* wisdom, care, and true human flourishing as competitive, stable attractors rather than vulnerable outliers?  
* 1,000 page document articulating humanity’s CEV  
* Caring & enlightened AGI

Cutting Room Floor

* What is the project of alignment?  
  * "How can we ensure what is optimized by machine learning models is good?"  
* Why does alignment not just happen automatically?  
* What is the field focused on? What are the questions most alignment research is concerned with? What's essential, what are they missing?  
* Levels of Alignment: Technical, Institutional, Cultural, Civilizational  
  * Alignment isn’t just about safety  
  * Alignment isn’t just about values  
    * A worldview, a story, a philosophy of the good, a vision of the future…  
* What are we aligning AI to?  
* **"What is good?"**  
  * "alignment with operator intent" — why is this insufficient?  
  * Why does much of the field sidestep that question?  
  * moral relativism, revealed preferences, etc preventing notions of wisdom?  
* What is the operating notion of "human values" in the field?  
* What are the limits of revealed preferences as a measure of benefit?  
* What are human values in the MAI sense?  
* How does alignment need to be contextualized?  
  * \> Technical Alignment vs. Flourishing Futures  
  * CETAI: Civilizationally Embedded Transformative AI  
  * **How does this reframe the alignment question?**  
* What is wisdom?  
* "What do people value?" vs. "What's important?"  
  * What are good human values,  
    existentially important human values?  
  * What do we need to align/attune human values to?  
* More or less wise? Natural hierarchies of wisdom?  
* AI and parenting: What would be a good relationship with a vastly more intelligent (and hopefully wise) entity?  
* The possibility of superwisdom, wisdom explosion, etc
